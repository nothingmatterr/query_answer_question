

#  Public042.pdf


1. Neural network lÃ  gÃ¬
Con chÃ³ cÃ³ thá»ƒ phÃ¢n biá»‡t Ä‘Æ°á»£c ngÆ°á»i thÃ¢n trong gia Ä‘Ã¬nh vÃ  ngÆ°á»i láº¡ hay Ä‘á»©a tráº» cÃ³ thá»ƒ
phÃ¢n biá»‡t Ä‘Æ°á»£c cÃ¡c con váº­t. Nhá»¯ng viá»‡c tÆ°á»Ÿng chá»«ng nhÆ° ráº¥t Ä‘Æ¡n giáº£n nhÆ°ng láº¡i cá»±c kÃ¬
khÃ³ Ä‘á»ƒ thá»±c hiá»‡n báº±ng mÃ¡y tÃ­nh. Váº­y sá»± khÃ¡c biá»‡t náº±m á»Ÿ Ä‘Ã¢u? CÃ¢u tráº£ lá»i náº±m á»Ÿ cáº¥u
trÃºc bá»™ nÃ£o vá»›i lÆ°á»£ng lá»›n cÃ¡c nÆ¡-ron tháº§n kinh liÃªn káº¿t vá»›i nhau. Liá»‡u mÃ¡y tÃ­nh cÃ³ thá»ƒ
mÃ´ phá»ng láº¡i cáº¥u trÃºc bá»™ nÃ£o Ä‘á»ƒ giáº£i cÃ¡c bÃ i toÃ¡n trÃªn ???
Neural lÃ  tÃ­nh tá»« cá»§a neuron (nÆ¡-ron), network chá»‰ cáº¥u trÃºc, cÃ¡ch cÃ¡c nÆ¡-ron Ä‘Ã³ liÃªn káº¿t
vá»›i nhau, nÃªn neural network (NN) lÃ  má»™t há»‡ thá»‘ng tÃ­nh toÃ¡n láº¥y cáº£m há»©ng tá»« sá»± hoáº¡t
Ä‘á»™ng cá»§a cÃ¡c nÆ¡-ron trong há»‡ tháº§n kinh.
Hoáº¡t Ä‘á»™ng cá»§a cÃ¡c nÆ¡-ron 1.1
NÆ¡-ron lÃ  Ä‘Æ¡n vá»‹ cÆ¡ báº£n cáº¥u táº¡o há»‡ thá»‘ng tháº§n kinh vÃ  lÃ  thÃ nh pháº§n quan trá»ng nháº¥t
cá»§a nÃ£o. Äáº§u chÃºng ta gá»“m khoáº£ng 10 triá»‡u nÆ¡-ron vÃ  má»—i nÆ¡-ron láº¡i liÃªn káº¿t vá»›i táº§m


# nÆ¡-ron khÃ¡c.


á» má»—i nÆ¡-ron cÃ³ pháº§n thÃ¢n (soma) chá»©a nhÃ¢n, cÃ¡c tÃ­n hiá»‡u Ä‘áº§u vÃ o qua sá»£i nhÃ¡nh
(dendrites) vÃ  cÃ¡c tÃ­n hiá»‡u Ä‘áº§u ra qua sá»£i trá»¥c (axon) káº¿t ná»‘i vá»›i cÃ¡c nÆ¡-ron khÃ¡c. Hiá»ƒu
Ä‘Æ¡n giáº£n má»—i nÆ¡-ron nháº­n dá»¯ liá»‡u Ä‘áº§u vÃ o qua sá»£i nhÃ¡nh vÃ  truyá»n dá»¯ liá»‡u Ä‘áº§u ra qua
sá»£i trá»¥c, Ä‘áº¿n cÃ¡c sá»£i nhÃ¡nh cá»§a cÃ¡c nÆ¡-ron khÃ¡c.
Má»—i nÆ¡-ron nháº­n xung Ä‘iá»‡n tá»« cÃ¡c nÆ¡-ron khÃ¡c qua sá»£i nhÃ¡nh. Náº¿u cÃ¡c xung Ä‘iá»‡n nÃ y
Ä‘á»§ lá»›n Ä‘á»ƒ kÃ­ch hoáº¡t nÆ¡-ron, thÃ¬ tÃ­n hiá»‡u nÃ y Ä‘i qua sá»£i trá»¥c Ä‘áº¿n cÃ¡c sá»£i nhÃ¡nh cá»§a cÃ¡c
nÆ¡-ron khÃ¡c.
HÃ¬nh 5.1: Táº¿ bÃ o tháº§n kinh [14]
=> á» má»—i nÆ¡-ron cáº§n quyáº¿t Ä‘á»‹nh cÃ³ kÃ­ch hoáº¡t nÆ¡-ron Ä‘áº¥y hay khÃ´ng. TÆ°Æ¡ng tá»± cÃ¡c hoáº¡t
Ä‘á»™ng cá»§a hÃ m sigmoid bÃ i trÆ°á»›c.
Tuy nhiÃªn NN chá»‰ lÃ  láº¥y cáº£m há»©ng tá»« nÃ£o bá»™ vÃ  cÃ¡ch nÃ³ hoáº¡t Ä‘á»™ng, chá»© khÃ´ng pháº£i
báº¯t chÆ°á»›c toÃ n bá»™ cÃ¡c chá»©c nÄƒng cá»§a nÃ³. Viá»‡c chÃ­nh cá»§a chÃºng ta lÃ  dÃ¹ng mÃ´ hÃ¬nh Ä‘áº¥y
Ä‘i giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n chÃºng ta cáº§n.
2. MÃ´ hÃ¬nh neural network
Logistic regression 2.1
Logistic regression lÃ  mÃ´ hÃ¬nh neural network Ä‘Æ¡n giáº£n nháº¥t chá»‰ vá»›i input layer vÃ  output
layer.
MÃ´ hÃ¬nh cá»§a logistic regression tá»« bÃ i trÆ°á»›c lÃ : yË†=Ïƒ(w0+w1âˆ—x1+w2âˆ—x2). CÃ³ 2 bÆ°á»›c:
TÃ­nh tá»•ng linear: z =1âˆ—w0+x1âˆ—w1+x2âˆ—w2
Ãp dá»¥ng sigmoid function: yË†=Ïƒ(z)
Äá»ƒ biá»ƒu diá»…n gá»n láº¡i ta sáº½ gá»™p hai bÆ°á»›c trÃªn thÃ nh má»™t trÃªn biá»ƒu Ä‘á»“ nhÆ° hÃ¬nh 5.2.
HÃ¬nh 5.2: MÃ´ hÃ¬nh logistic regression
Há»‡ sá»‘ w0 Ä‘Æ°á»£c gá»i lÃ  bias. Äá»ƒ Ã½ tá»« nhá»¯ng bÃ i trÆ°á»›c Ä‘áº¿n giá» dá»¯ liá»‡u khi tÃ­nh toÃ¡n luÃ´n
Ä‘Æ°á»£c thÃªm 1 Ä‘á»ƒ tÃ­nh há»‡ sá»‘ bias w0 . Táº¡i sao láº¡i cáº§n há»‡ sá»‘ bias? Quay láº¡i vá»›i bÃ i 1, phÆ°Æ¡ng
trÃ¬nh Ä‘Æ°á»ng tháº³ng sáº½ tháº¿ nÃ o náº¿u bá» w0, phÆ°Æ¡ng trÃ¬nh giá» cÃ³ dáº¡ng: y = w1âˆ—x, sáº½ luÃ´n Ä‘i
qua gá»‘c tá»a Ä‘á»™ vÃ  nÃ³ khÃ´ng tá»•ng quÃ¡t hÃ³a phÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng tháº³ng nÃªn cÃ³ thá»ƒ khÃ´ng
tÃ¬m Ä‘Æ°á»£c phÆ°Æ¡ng trÃ¬nh mong muá»‘n. => Viá»‡c thÃªm bias (há»‡ sá»‘ tá»± do) lÃ  ráº¥t quan trá»ng.
HÃ m sigmoid á»Ÿ Ä‘Ã¢y Ä‘Æ°á»£c gá»i lÃ  activation function.
MÃ´ hÃ¬nh tá»•ng quÃ¡t 2.2
Layer Ä‘áº§u tiÃªn lÃ  input layer, cÃ¡c layer á»Ÿ giá»¯a Ä‘Æ°á»£c gá»i lÃ  hidden layer, layer cuá»‘i cÃ¹ng
Ä‘Æ°á»£c gá»i lÃ  output layer. CÃ¡c hÃ¬nh trÃ²n Ä‘Æ°á»£c gá»i lÃ  node.
Má»—i mÃ´ hÃ¬nh luÃ´n cÃ³ 1 input layer, 1 output layer, cÃ³ thá»ƒ cÃ³ hoáº·c khÃ´ng cÃ¡c hidden
layer. Tá»•ng sá»‘ layer trong mÃ´ hÃ¬nh Ä‘Æ°á»£c quy Æ°á»›c lÃ  sá»‘ layer - 1 (khÃ´ng tÃ­nh input layer).
VÃ­ dá»¥ nhÆ° á»Ÿ hÃ¬nh trÃªn cÃ³ 1 input layer, 2 hidden layer vÃ  1 output layer. Sá»‘ lÆ°á»£ng layer
cá»§a mÃ´ hÃ¬nh lÃ  3 layer.
Má»—i node trong hidden layer vÃ  output layer :
LiÃªn káº¿t vá»›i táº¥t cáº£ cÃ¡c node á»Ÿ layer trÆ°á»›c Ä‘Ã³ vá»›i cÃ¡c há»‡ sá»‘ w riÃªng.
Má»—i node cÃ³ 1 há»‡ sá»‘ bias b riÃªng.
Diá»…n ra 2 bÆ°á»›c: tÃ­nh tá»•ng linear vÃ  Ã¡p dá»¥ng activation function.
KÃ­ hiá»‡u 2.3
l(i). Sá»‘ node trong hidden layer thá»© i lÃ 
W(k) l(kâˆ’1) âˆ—l(k) Ma tráº­n kÃ­ch thÆ°á»›c lÃ  ma tráº­n há»‡ sá»‘ giá»¯a layer (k-1) vÃ  layer k, trong Ä‘Ã³
w(ijk) lÃ  há»‡ sá»‘ káº¿t ná»‘i tá»« node thá»© i cá»§a layer k-1 Ä‘áº¿n node thá»© j cá»§a layer k.
HÃ¬nh 5.3: MÃ´ hÃ¬nh neural network
Vector ğ‘(ğ‘˜) kÃ­ch thÆ°á»›c ğ‘™ğ‘˜âˆ—1 lÃ  há»‡ sá»‘ bias cá»§a cÃ¡c node trong layer k, trong Ä‘Ã³ b(ik) lÃ  bias
cá»§a node thá»© i trong layer k.
(l)
bi(l) Vá»›i node thá»© i trong layer l cÃ³ bias thá»±c hiá»‡n 2 bÆ°á»›c:
- TÃ­nh tá»•ng táº¥t cáº£ cÃ¡c node trong layer trÆ°á»›c nhÃ¢n vá»›i há»‡ sá»‘ w tÆ°Æ¡ng á»©ng, rá»“i
cá»™ng vá»›i bias b.
ai(l) (l)) Ãp dá»¥ng activation function: =Ïƒ(zi
z(k) l(k) Vector kÃ­ch thÆ°á»›c âˆ—1 lÃ  giÃ¡ trá»‹ cÃ¡c node trong layer k sau bÆ°á»›c tÃ­nh tá»•ng linear.
a(k) l(k) Vector kÃ­ch thÆ°á»›c âˆ—1 lÃ  giÃ¡ trá»‹ cá»§a cÃ¡c node trong layer k sau khi Ã¡p dá»¥ng hÃ m
activation function.
(l(0) MÃ´ hÃ¬nh neural network trÃªn gá»“m 3 layer. Input layer cÃ³ 2 node =2), hidden layer 1
cÃ³ 3 node, hidden layer 2 cÃ³ 3 node vÃ  output layer cÃ³ 1 node.
Do má»—i node trong hidden layer vÃ  output layer Ä‘á»u cÃ³ bias nÃªn trong input layer vÃ 
hidden layer cáº§n thÃªm node 1 Ä‘á»ƒ tÃ­nh bias (nhÆ°ng khÃ´ng tÃ­nh vÃ o tá»•ng sá»‘ node layer cÃ³).
3. Feedforward
Äá»ƒ nháº¥t quÃ¡n vá» máº·t kÃ½ hiá»‡u, gá»i input layer lÃ  a(0)(= x) kÃ­ch thÆ°á»›c 2*1.
TÆ°Æ¡ng tá»± ta cÃ³:
z(2) =(W(2))T âˆ—a(1) +b(2)
a(2) =Ïƒ(z(2))
z(3) =(W(3))T âˆ—a(2) +b(3)
yË†= a(3) =Ïƒ(z(3))
HÃ¬nh 5.4: Feedforward
4. Logistic regression vá»›i toÃ¡n tá»­ XOR
Pháº§n nÃ y khÃ´ng báº¯t buá»™c, nÃ³ giÃºp giáº£i thÃ­ch viá»‡c cÃ³ nhiá»u layer hÆ¡n thÃ¬ mÃ´ hÃ¬nh sáº½ giáº£i
quyáº¿t Ä‘Æ°á»£c cÃ¡c bÃ i toÃ¡n phá»©c táº¡p hÆ¡n. Cá»¥ thá»ƒ lÃ  mÃ´ hÃ¬nh logistic regression bÃ i trÆ°á»›c
khÃ´ng biá»ƒu diá»…n Ä‘Æ°á»£c toÃ¡n tá»­ XOR nhÆ°ng náº¿u thÃªm 1 hidden layer vá»›i 2 node á»Ÿ giá»¯a
input layer vÃ  output layer thÃ¬ cÃ³ thá»ƒ biá»ƒu diá»…n Ä‘Æ°á»£c toÃ¡n tá»­ XOR.
AND, OR, XOR lÃ  cÃ¡c phÃ©p toÃ¡n thá»±c hiá»‡n phÃ©p tÃ­nh trÃªn bit. Tháº¿ bit lÃ  gÃ¬? báº¡n khÃ´ng
cáº§n quan tÃ¢m, chá»‰ cáº§n biáº¿t má»—i bit nháº­n 1 trong 2 giÃ¡ trá»‹ lÃ  0 hoáº·c 1.
NOT 4.1
PhÃ©p tÃ­nh NOT cá»§a 1 bit cho ra giÃ¡ trá»‹ ngÆ°á»£c láº¡i.
A NOT(A)
0 1
1 0
AND 4.2
PhÃ©p tÃ­nh AND cá»§a 2 bit cho giÃ¡ trá»‹ 1 náº¿u cáº£ 2 bit báº±ng 1 vÃ  cho giÃ¡ trá»‹ báº±ng 0 trong cÃ¡c
trÆ°á»ng há»£p cÃ²n láº¡i. Báº£ng chÃ¢n lÃ½
A B A AND B
0 0 0
0 1 0
1 0 0
1 1 1
OR 4.3
PhÃ©p tÃ­nh OR cá»§a 2 bit cho giÃ¡ trá»‹ 1 náº¿u 1 trong 2 bit báº±ng 1 vÃ  cho giÃ¡ trá»‹ báº±ng 0 trong
cÃ¡c trÆ°á»ng há»£p cÃ²n láº¡i. Báº£ng chÃ¢n lÃ½
A B A OR B
0 0 0
0 1 1
1 0 1
1 1 1
XOR 4.4
PhÃ©p tÃ­nh XOR cá»§a 2 bit cho giÃ¡ trá»‹ 1 náº¿u Ä‘Ãºng 1 trong 2 bit báº±ng 1 vÃ  cho giÃ¡ trá»‹ báº±ng
0 trong cÃ¡c trÆ°á»ng há»£p cÃ²n láº¡i. Báº£ng chÃ¢n lÃ½
A B A XOR B
0 0 0
0 1 1
1 0 1
1 1 0
Khi thiáº¿t láº­p bÃ i toÃ¡n logistic regression, ta cÃ³ Ä‘á»“ thá»‹
RÃµ rÃ ng lÃ  khÃ´ng thá»ƒ dÃ¹ng má»™t Ä‘Æ°á»ng tháº³ng Ä‘á»ƒ phÃ¢n chia dá»¯ liá»‡u thÃ nh 2 miá»n. NÃªn
khi báº¡n dÃ¹ng gradient descent vÃ o bÃ i toÃ¡n XOR thÃ¬ báº¥t ká»ƒ báº¡n cháº¡y bÆ°á»›c 2 bao nhiÃªu
láº§n hay chá»‰nh learning_rate tháº¿ nÃ o thÃ¬ váº«n khÃ´ng ra Ä‘Æ°á»£c káº¿t quáº£ nhÆ° mong muá»‘n.
Logistic regression nhÆ° bÃ i trÆ°á»›c khÃ´ng thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y, giá» cáº§n má»™t
giáº£i phÃ¡p má»›i !!!
Ãp dá»¥ng cÃ¡c kiáº¿n thá»©c vá» bit á»Ÿ trÃªn láº¡i, ta cÃ³:
A B A XOR B A AND B NOT A OR B (NOT(A AND B)
(A AND B)
AND (A OR B))
0 0 0 0 1 0 0
0 1 1 0 1 1 1
1 0 1 0 1 1 1
1 1 0 1 0 1 0
Do Ä‘Ã³: A XOR B = (NOT(A AND B) AND (A OR B)), váº­y Ä‘á»ƒ tÃ­nh Ä‘Æ°á»£c XOR ta káº¿t
há»£p NOT(AND) vÃ  OR sau Ä‘Ã³ tÃ­nh phÃ©p tÃ­nh AND.
HÃ¬nh 5.12: MÃ´ hÃ¬nh XOR
NhÃ¬n cÃ³ váº» rá»‘i nhá»‰, cÃ¹ng phÃ¢n tÃ­ch nhÃ©:
node NOT(x1 AND x2) chÃ­nh lÃ  tá»« hÃ¬nh 5.10, vá»›i 3 mÅ©i tÃªn chá»‰ Ä‘áº¿n tá»« 1,x1,x2 vá»›i há»‡ sá»‘
w0,w1,w2 tÆ°Æ¡ng á»©ng lÃ  1.5, -1, -1.
node tÃ­nh x1 OR x2 lÃ  tá»« hÃ¬nh 5.11
node trong output layer lÃ  phÃ©p tÃ­nh AND tá»« 2 node cá»§a layer trÆ°á»›c, giÃ¡ trá»‹ há»‡ sá»‘ tá»« hÃ¬nh
1 mang xuá»‘ng.
Nháº­n xÃ©t: mÃ´ hÃ¬nh logistic regression khÃ´ng giáº£i quyáº¿t Ä‘Æ°á»£c bÃ i toÃ¡n XOR nhÆ°ng mÃ´
hÃ¬nh má»›i thÃ¬ giáº£i quyáº¿t Ä‘Æ°á»£c bÃ i toÃ¡n XOR. ÄÃ¢u lÃ  sá»± khÃ¡c nhau:
Logistic regression chá»‰ cÃ³ input layer vÃ  output layer
MÃ´ hÃ¬nh má»›i cÃ³ 1 hidden layer cÃ³ 2 node á»Ÿ giá»¯a input layer vÃ  output layer.
CÃ ng nhiá»u layer vÃ  node thÃ¬ cÃ ng giáº£i quyáº¿t Ä‘Æ°á»£c cÃ¡c bÃ i toÃ¡n phá»©c táº¡p hÆ¡n.